# Faithful Features

## Overview

This project was created for [Apart Research's Reprogramming AI Models hackathon](https://www.apartresearch.com/project/faithful-or-factual-tuning-mistake-acknowledgment-in-llms) with Goodfire that took place Nov 22 - Nov 24 2024. View the writeup [here](https://www.apartresearch.com/project/faithful-or-factual-tuning-mistake-acknowledgment-in-llms). In this code, we create a dataset of Llama-3.1-70B responding to MMLU questions using chain of thought reasoning combined with a version of that reasoning that leads to an incorrect answer generated by GPT-4o. Finally, we provide this incorrect reasoning through variants of Llama-3.1-70B with features related to acknowledging mistakes varied by set increments as if it is its own reasoning to observe how likely each variant is to be faithful and generate the answer following the incorrect reasoning or be factual and generate the correct answer.

## Usage

To run the experiment locally:

0. pip install goodfire, pandas, openai, numpy, datasets.

1. Set up your environment variables:
   - `OPENAI_API_KEY`: Your OpenAI API key
   - `GOODFIRE_API_KEY`: Your Goodfire API key

2. Run `python main.py`

If you would like to create a new reasoning dataset, specify a filename with the --dataset_filename command line argument. Otherwise, the dataset used for generating the results in the submission will be used by default. View `main.py` for a list of other useful command line arguments.

## Project Structure

- `main.py`: The starting point for running this repo's code.
- `dataset_curation.py`: Generates the reasoning dataset.
- `experiment_generation.py`: Runs the variants against the reasoning dataset and saves the results to a csv file.
- `analysis_viz.ipynb.ipynb`: Creates figures and graphs for further analysis.

## Authors

- Mia Hopman
- Jack Wittmayer
- Daniel Donnelly




